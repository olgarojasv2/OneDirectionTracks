{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c720e8a5-f2e5-4f3e-8863-af20b8d973f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==3.7.1\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.1/en_core_web_sm-3.7.1-py3-none-any.whl (12.8 MB)\n",
      "     ---------------------------------------- 0.0/12.8 MB ? eta -:--:--\n",
      "     --------- ------------------------------ 2.9/12.8 MB 16.7 MB/s eta 0:00:01\n",
      "     ----------------------- ---------------- 7.6/12.8 MB 20.4 MB/s eta 0:00:01\n",
      "     --------------------------------------  12.6/12.8 MB 21.3 MB/s eta 0:00:01\n",
      "     --------------------------------------- 12.8/12.8 MB 20.1 MB/s eta 0:00:00\n",
      "Requirement already satisfied: spacy<3.8.0,>=3.7.2 in c:\\users\\olga\\anaconda4\\envs\\asigmentlab\\lib\\site-packages (from en-core-web-sm==3.7.1) (3.7.2)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\olga\\anaconda4\\envs\\asigmentlab\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\olga\\anaconda4\\envs\\asigmentlab\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.4)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\olga\\anaconda4\\envs\\asigmentlab\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.7)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\olga\\anaconda4\\envs\\asigmentlab\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.6)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\olga\\anaconda4\\envs\\asigmentlab\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.6)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.1.8 in c:\\users\\olga\\anaconda4\\envs\\asigmentlab\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.2.2)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\olga\\anaconda4\\envs\\asigmentlab\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.9.1)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\olga\\anaconda4\\envs\\asigmentlab\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.4.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\olga\\anaconda4\\envs\\asigmentlab\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in c:\\users\\olga\\anaconda4\\envs\\asigmentlab\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.3.4)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in c:\\users\\olga\\anaconda4\\envs\\asigmentlab\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.9.0)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in c:\\users\\olga\\anaconda4\\envs\\asigmentlab\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (5.2.1)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\olga\\anaconda4\\envs\\asigmentlab\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.66.5)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\olga\\anaconda4\\envs\\asigmentlab\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.32.3)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in c:\\users\\olga\\anaconda4\\envs\\asigmentlab\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.8.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\olga\\anaconda4\\envs\\asigmentlab\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.1.4)\n",
      "Requirement already satisfied: setuptools in c:\\users\\olga\\anaconda4\\envs\\asigmentlab\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (75.1.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\olga\\anaconda4\\envs\\asigmentlab\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (24.1)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\olga\\anaconda4\\envs\\asigmentlab\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.3.0)\n",
      "Requirement already satisfied: numpy>=1.19.0 in c:\\users\\olga\\anaconda4\\envs\\asigmentlab\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.26.4)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\olga\\anaconda4\\envs\\asigmentlab\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in c:\\users\\olga\\anaconda4\\envs\\asigmentlab\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.20.1)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in c:\\users\\olga\\anaconda4\\envs\\asigmentlab\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\olga\\anaconda4\\envs\\asigmentlab\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\olga\\anaconda4\\envs\\asigmentlab\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\olga\\anaconda4\\envs\\asigmentlab\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\olga\\anaconda4\\envs\\asigmentlab\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2024.8.30)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in c:\\users\\olga\\anaconda4\\envs\\asigmentlab\\lib\\site-packages (from thinc<8.3.0,>=8.1.8->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\olga\\anaconda4\\envs\\asigmentlab\\lib\\site-packages (from thinc<8.3.0,>=8.1.8->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\olga\\anaconda4\\envs\\asigmentlab\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.4.6)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\olga\\anaconda4\\envs\\asigmentlab\\lib\\site-packages (from typer<0.10.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.1.7)\n",
      "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in c:\\users\\olga\\anaconda4\\envs\\asigmentlab\\lib\\site-packages (from weasel<0.4.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\olga\\anaconda4\\envs\\asigmentlab\\lib\\site-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.1.3)\n",
      "[+] Download and installation successful\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "# Import spacy\n",
    "import spacy\n",
    "\n",
    "# Install English language model\n",
    "!spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0a35c7db-d5fc-413b-8c54-e093a945cd62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import os to upload documents and metadata\n",
    "import os\n",
    "\n",
    "# Load spaCy visualizer\n",
    "from spacy import displacy\n",
    "\n",
    "# Import pandas DataFrame packages\n",
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "\n",
    "# Import graphing package\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1872e94b-d2be-4508-8871-849694e86a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the English language model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Base directory\n",
    "base_dir = \"One Direction.texts\"\n",
    "\n",
    "# Lists to store data\n",
    "filenames = []\n",
    "titles = []\n",
    "artists = []\n",
    "albums = []\n",
    "documents = []\n",
    "texts = []\n",
    "tokens = []\n",
    "lemmas = []\n",
    "pos = []\n",
    "\n",
    "# Iterate through albums\n",
    "for album in os.listdir(base_dir):\n",
    "    album_path = os.path.join(base_dir, album)\n",
    "    if os.path.isdir(album_path):\n",
    "        # Iterate through songs in the album\n",
    "        for song_file in os.listdir(album_path):\n",
    "            if song_file.endswith('.txt'):\n",
    "                # Extract song title (remove .txt extension)\n",
    "                title = os.path.splitext(song_file)[0]\n",
    "    \n",
    "                # Read lyrics from the file\n",
    "                with open(os.path.join(album_path, song_file), 'r', encoding='utf-8') as inf:\n",
    "                    document = inf.read()\n",
    "                \n",
    "                # Process the text with spaCy\n",
    "                doc = nlp(document)\n",
    "                \n",
    "                # Append data to lists\n",
    "                filenames.append(song_file)\n",
    "                titles.append(title)\n",
    "                artists.append('One Direction')\n",
    "                albums.append(album)\n",
    "                documents.append(document)  \n",
    "                #tokenization [(toke.text) for token in doc]\n",
    "                tokens.append([token.text for token in doc])\n",
    "                lemmas.append([token.lemma_ for token in doc])\n",
    "                #I am doing the text enrichment of SpaCy aka toke.pos\n",
    "                pos.append([token.pos_ for token in doc])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5acfa0ac-157d-444d-893b-c7aa609360a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrame\n",
    "paper_df = pd.DataFrame({\n",
    "    \"Filename\": filenames,\n",
    "    \"Title\": titles,\n",
    "    \"Artist\": artists,\n",
    "    \"Album\": albums,\n",
    "    \"Document\": documents,\n",
    "    \"Tokens\": tokens,\n",
    "    \"Lemmas\": lemmas,\n",
    "    \"Tags\": pos\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c94f336a-58f0-4651-acce-fbf3ca8706cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filename</th>\n",
       "      <th>Title</th>\n",
       "      <th>Artist</th>\n",
       "      <th>Album</th>\n",
       "      <th>Document</th>\n",
       "      <th>Tokens</th>\n",
       "      <th>Lemmas</th>\n",
       "      <th>Tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>back for you.txt</td>\n",
       "      <td>back for you</td>\n",
       "      <td>One Direction</td>\n",
       "      <td>Take me Home</td>\n",
       "      <td>Back for you\\n\\nWhenever I close my eyes I pic...</td>\n",
       "      <td>[Back, for, you, \\n\\n, Whenever, I, close, my,...</td>\n",
       "      <td>[back, for, you, \\n\\n, whenever, I, close, my,...</td>\n",
       "      <td>[ADV, ADP, PRON, SPACE, SCONJ, PRON, VERB, PRO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Change my mind.txt</td>\n",
       "      <td>Change my mind</td>\n",
       "      <td>One Direction</td>\n",
       "      <td>Take me Home</td>\n",
       "      <td>Change my mind\\n\\nThe end of the night\\nWe sho...</td>\n",
       "      <td>[Change, my, mind, \\n\\n, The, end, of, the, ni...</td>\n",
       "      <td>[change, my, mind, \\n\\n, the, end, of, the, ni...</td>\n",
       "      <td>[VERB, PRON, NOUN, SPACE, DET, NOUN, ADP, DET,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cmon cmon.txt</td>\n",
       "      <td>Cmon cmon</td>\n",
       "      <td>One Direction</td>\n",
       "      <td>Take me Home</td>\n",
       "      <td>Cmon cmon\\n\\nThe one that I came with\\nShe had...</td>\n",
       "      <td>[Cmon, cmon, \\n\\n, The, one, that, I, came, wi...</td>\n",
       "      <td>[Cmon, cmon, \\n\\n, the, one, that, I, come, wi...</td>\n",
       "      <td>[PROPN, PROPN, SPACE, DET, NOUN, PRON, PRON, V...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Heart attack.txt</td>\n",
       "      <td>Heart attack</td>\n",
       "      <td>One Direction</td>\n",
       "      <td>Take me Home</td>\n",
       "      <td>Heart attack\\n\\nBaby you got me sick\\nI don’t ...</td>\n",
       "      <td>[Heart, attack, \\n\\n, Baby, you, got, me, sick...</td>\n",
       "      <td>[heart, attack, \\n\\n, Baby, you, get, I, sick,...</td>\n",
       "      <td>[NOUN, NOUN, SPACE, PROPN, PRON, VERB, PRON, A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I would.txt</td>\n",
       "      <td>I would</td>\n",
       "      <td>One Direction</td>\n",
       "      <td>Take me Home</td>\n",
       "      <td>I would\\n\\nLately I found myself thinking\\nBee...</td>\n",
       "      <td>[I, would, \\n\\n, Lately, I, found, myself, thi...</td>\n",
       "      <td>[I, would, \\n\\n, lately, I, find, myself, thin...</td>\n",
       "      <td>[PRON, AUX, SPACE, ADV, PRON, VERB, PRON, VERB...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Filename           Title         Artist         Album  \\\n",
       "0    back for you.txt    back for you  One Direction  Take me Home   \n",
       "1  Change my mind.txt  Change my mind  One Direction  Take me Home   \n",
       "2       Cmon cmon.txt       Cmon cmon  One Direction  Take me Home   \n",
       "3    Heart attack.txt    Heart attack  One Direction  Take me Home   \n",
       "4         I would.txt         I would  One Direction  Take me Home   \n",
       "\n",
       "                                            Document  \\\n",
       "0  Back for you\\n\\nWhenever I close my eyes I pic...   \n",
       "1  Change my mind\\n\\nThe end of the night\\nWe sho...   \n",
       "2  Cmon cmon\\n\\nThe one that I came with\\nShe had...   \n",
       "3  Heart attack\\n\\nBaby you got me sick\\nI don’t ...   \n",
       "4  I would\\n\\nLately I found myself thinking\\nBee...   \n",
       "\n",
       "                                              Tokens  \\\n",
       "0  [Back, for, you, \\n\\n, Whenever, I, close, my,...   \n",
       "1  [Change, my, mind, \\n\\n, The, end, of, the, ni...   \n",
       "2  [Cmon, cmon, \\n\\n, The, one, that, I, came, wi...   \n",
       "3  [Heart, attack, \\n\\n, Baby, you, got, me, sick...   \n",
       "4  [I, would, \\n\\n, Lately, I, found, myself, thi...   \n",
       "\n",
       "                                              Lemmas  \\\n",
       "0  [back, for, you, \\n\\n, whenever, I, close, my,...   \n",
       "1  [change, my, mind, \\n\\n, the, end, of, the, ni...   \n",
       "2  [Cmon, cmon, \\n\\n, the, one, that, I, come, wi...   \n",
       "3  [heart, attack, \\n\\n, Baby, you, get, I, sick,...   \n",
       "4  [I, would, \\n\\n, lately, I, find, myself, thin...   \n",
       "\n",
       "                                                Tags  \n",
       "0  [ADV, ADP, PRON, SPACE, SCONJ, PRON, VERB, PRO...  \n",
       "1  [VERB, PRON, NOUN, SPACE, DET, NOUN, ADP, DET,...  \n",
       "2  [PROPN, PROPN, SPACE, DET, NOUN, PRON, PRON, V...  \n",
       "3  [NOUN, NOUN, SPACE, PROPN, PRON, VERB, PRON, A...  \n",
       "4  [PRON, AUX, SPACE, ADV, PRON, VERB, PRON, VERB...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the first few rows of the DataFrame\n",
    "\n",
    "paper_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f9458868-bb09-4a3c-994a-ca8d48215f72",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:1: SyntaxWarning: invalid escape sequence '\\s'\n",
      "<>:1: SyntaxWarning: invalid escape sequence '\\s'\n",
      "C:\\Users\\Olga\\AppData\\Local\\Temp\\ipykernel_1452\\3373195460.py:1: SyntaxWarning: invalid escape sequence '\\s'\n",
      "  paper_df['Document'] = paper_df['Document'].str.replace('\\s+', ' ', regex=True).str.strip()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filename</th>\n",
       "      <th>Title</th>\n",
       "      <th>Artist</th>\n",
       "      <th>Album</th>\n",
       "      <th>Document</th>\n",
       "      <th>Tokens</th>\n",
       "      <th>Lemmas</th>\n",
       "      <th>Tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>back for you.txt</td>\n",
       "      <td>back for you</td>\n",
       "      <td>One Direction</td>\n",
       "      <td>Take me Home</td>\n",
       "      <td>Back for you Whenever I close my eyes I pictur...</td>\n",
       "      <td>[Back, for, you, \\n\\n, Whenever, I, close, my,...</td>\n",
       "      <td>[back, for, you, \\n\\n, whenever, I, close, my,...</td>\n",
       "      <td>[ADV, ADP, PRON, SPACE, SCONJ, PRON, VERB, PRO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Change my mind.txt</td>\n",
       "      <td>Change my mind</td>\n",
       "      <td>One Direction</td>\n",
       "      <td>Take me Home</td>\n",
       "      <td>Change my mind The end of the night We should ...</td>\n",
       "      <td>[Change, my, mind, \\n\\n, The, end, of, the, ni...</td>\n",
       "      <td>[change, my, mind, \\n\\n, the, end, of, the, ni...</td>\n",
       "      <td>[VERB, PRON, NOUN, SPACE, DET, NOUN, ADP, DET,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cmon cmon.txt</td>\n",
       "      <td>Cmon cmon</td>\n",
       "      <td>One Direction</td>\n",
       "      <td>Take me Home</td>\n",
       "      <td>Cmon cmon The one that I came with She had to ...</td>\n",
       "      <td>[Cmon, cmon, \\n\\n, The, one, that, I, came, wi...</td>\n",
       "      <td>[Cmon, cmon, \\n\\n, the, one, that, I, come, wi...</td>\n",
       "      <td>[PROPN, PROPN, SPACE, DET, NOUN, PRON, PRON, V...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Heart attack.txt</td>\n",
       "      <td>Heart attack</td>\n",
       "      <td>One Direction</td>\n",
       "      <td>Take me Home</td>\n",
       "      <td>Heart attack Baby you got me sick I don’t know...</td>\n",
       "      <td>[Heart, attack, \\n\\n, Baby, you, got, me, sick...</td>\n",
       "      <td>[heart, attack, \\n\\n, Baby, you, get, I, sick,...</td>\n",
       "      <td>[NOUN, NOUN, SPACE, PROPN, PRON, VERB, PRON, A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I would.txt</td>\n",
       "      <td>I would</td>\n",
       "      <td>One Direction</td>\n",
       "      <td>Take me Home</td>\n",
       "      <td>I would Lately I found myself thinking Been dr...</td>\n",
       "      <td>[I, would, \\n\\n, Lately, I, found, myself, thi...</td>\n",
       "      <td>[I, would, \\n\\n, lately, I, find, myself, thin...</td>\n",
       "      <td>[PRON, AUX, SPACE, ADV, PRON, VERB, PRON, VERB...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Filename           Title         Artist         Album  \\\n",
       "0    back for you.txt    back for you  One Direction  Take me Home   \n",
       "1  Change my mind.txt  Change my mind  One Direction  Take me Home   \n",
       "2       Cmon cmon.txt       Cmon cmon  One Direction  Take me Home   \n",
       "3    Heart attack.txt    Heart attack  One Direction  Take me Home   \n",
       "4         I would.txt         I would  One Direction  Take me Home   \n",
       "\n",
       "                                            Document  \\\n",
       "0  Back for you Whenever I close my eyes I pictur...   \n",
       "1  Change my mind The end of the night We should ...   \n",
       "2  Cmon cmon The one that I came with She had to ...   \n",
       "3  Heart attack Baby you got me sick I don’t know...   \n",
       "4  I would Lately I found myself thinking Been dr...   \n",
       "\n",
       "                                              Tokens  \\\n",
       "0  [Back, for, you, \\n\\n, Whenever, I, close, my,...   \n",
       "1  [Change, my, mind, \\n\\n, The, end, of, the, ni...   \n",
       "2  [Cmon, cmon, \\n\\n, The, one, that, I, came, wi...   \n",
       "3  [Heart, attack, \\n\\n, Baby, you, got, me, sick...   \n",
       "4  [I, would, \\n\\n, Lately, I, found, myself, thi...   \n",
       "\n",
       "                                              Lemmas  \\\n",
       "0  [back, for, you, \\n\\n, whenever, I, close, my,...   \n",
       "1  [change, my, mind, \\n\\n, the, end, of, the, ni...   \n",
       "2  [Cmon, cmon, \\n\\n, the, one, that, I, come, wi...   \n",
       "3  [heart, attack, \\n\\n, Baby, you, get, I, sick,...   \n",
       "4  [I, would, \\n\\n, lately, I, find, myself, thin...   \n",
       "\n",
       "                                                Tags  \n",
       "0  [ADV, ADP, PRON, SPACE, SCONJ, PRON, VERB, PRO...  \n",
       "1  [VERB, PRON, NOUN, SPACE, DET, NOUN, ADP, DET,...  \n",
       "2  [PROPN, PROPN, SPACE, DET, NOUN, PRON, PRON, V...  \n",
       "3  [NOUN, NOUN, SPACE, PROPN, PRON, VERB, PRON, A...  \n",
       "4  [PRON, AUX, SPACE, ADV, PRON, VERB, PRON, VERB...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paper_df['Document'] = paper_df['Document'].str.replace('\\s+', ' ', regex=True).str.strip()\n",
    "paper_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "92998912-d93d-4ce4-b2d5-96829cdafd55",
   "metadata": {},
   "outputs": [],
   "source": [
    "paper_df.to_csv('one_direction_songs_detailed.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2846056c-ebe5-4dbe-a648-e936451a8f2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filename</th>\n",
       "      <th>Title</th>\n",
       "      <th>Artist</th>\n",
       "      <th>Album</th>\n",
       "      <th>Document</th>\n",
       "      <th>Tokens</th>\n",
       "      <th>Lemmas</th>\n",
       "      <th>Tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>back for you.txt</td>\n",
       "      <td>back for you</td>\n",
       "      <td>One Direction</td>\n",
       "      <td>Take me Home</td>\n",
       "      <td>Back for you Whenever I close my eyes I pictur...</td>\n",
       "      <td>['Back', 'for', 'you', '\\n\\n', 'Whenever', 'I'...</td>\n",
       "      <td>['back', 'for', 'you', '\\n\\n', 'whenever', 'I'...</td>\n",
       "      <td>['ADV', 'ADP', 'PRON', 'SPACE', 'SCONJ', 'PRON...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Change my mind.txt</td>\n",
       "      <td>Change my mind</td>\n",
       "      <td>One Direction</td>\n",
       "      <td>Take me Home</td>\n",
       "      <td>Change my mind The end of the night We should ...</td>\n",
       "      <td>['Change', 'my', 'mind', '\\n\\n', 'The', 'end',...</td>\n",
       "      <td>['change', 'my', 'mind', '\\n\\n', 'the', 'end',...</td>\n",
       "      <td>['VERB', 'PRON', 'NOUN', 'SPACE', 'DET', 'NOUN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cmon cmon.txt</td>\n",
       "      <td>Cmon cmon</td>\n",
       "      <td>One Direction</td>\n",
       "      <td>Take me Home</td>\n",
       "      <td>Cmon cmon The one that I came with She had to ...</td>\n",
       "      <td>['Cmon', 'cmon', '\\n\\n', 'The', 'one', 'that',...</td>\n",
       "      <td>['Cmon', 'cmon', '\\n\\n', 'the', 'one', 'that',...</td>\n",
       "      <td>['PROPN', 'PROPN', 'SPACE', 'DET', 'NOUN', 'PR...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Heart attack.txt</td>\n",
       "      <td>Heart attack</td>\n",
       "      <td>One Direction</td>\n",
       "      <td>Take me Home</td>\n",
       "      <td>Heart attack Baby you got me sick I don’t know...</td>\n",
       "      <td>['Heart', 'attack', '\\n\\n', 'Baby', 'you', 'go...</td>\n",
       "      <td>['heart', 'attack', '\\n\\n', 'Baby', 'you', 'ge...</td>\n",
       "      <td>['NOUN', 'NOUN', 'SPACE', 'PROPN', 'PRON', 'VE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I would.txt</td>\n",
       "      <td>I would</td>\n",
       "      <td>One Direction</td>\n",
       "      <td>Take me Home</td>\n",
       "      <td>I would Lately I found myself thinking Been dr...</td>\n",
       "      <td>['I', 'would', '\\n\\n', 'Lately', 'I', 'found',...</td>\n",
       "      <td>['I', 'would', '\\n\\n', 'lately', 'I', 'find', ...</td>\n",
       "      <td>['PRON', 'AUX', 'SPACE', 'ADV', 'PRON', 'VERB'...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Filename           Title         Artist         Album  \\\n",
       "0    back for you.txt    back for you  One Direction  Take me Home   \n",
       "1  Change my mind.txt  Change my mind  One Direction  Take me Home   \n",
       "2       Cmon cmon.txt       Cmon cmon  One Direction  Take me Home   \n",
       "3    Heart attack.txt    Heart attack  One Direction  Take me Home   \n",
       "4         I would.txt         I would  One Direction  Take me Home   \n",
       "\n",
       "                                            Document  \\\n",
       "0  Back for you Whenever I close my eyes I pictur...   \n",
       "1  Change my mind The end of the night We should ...   \n",
       "2  Cmon cmon The one that I came with She had to ...   \n",
       "3  Heart attack Baby you got me sick I don’t know...   \n",
       "4  I would Lately I found myself thinking Been dr...   \n",
       "\n",
       "                                              Tokens  \\\n",
       "0  ['Back', 'for', 'you', '\\n\\n', 'Whenever', 'I'...   \n",
       "1  ['Change', 'my', 'mind', '\\n\\n', 'The', 'end',...   \n",
       "2  ['Cmon', 'cmon', '\\n\\n', 'The', 'one', 'that',...   \n",
       "3  ['Heart', 'attack', '\\n\\n', 'Baby', 'you', 'go...   \n",
       "4  ['I', 'would', '\\n\\n', 'Lately', 'I', 'found',...   \n",
       "\n",
       "                                              Lemmas  \\\n",
       "0  ['back', 'for', 'you', '\\n\\n', 'whenever', 'I'...   \n",
       "1  ['change', 'my', 'mind', '\\n\\n', 'the', 'end',...   \n",
       "2  ['Cmon', 'cmon', '\\n\\n', 'the', 'one', 'that',...   \n",
       "3  ['heart', 'attack', '\\n\\n', 'Baby', 'you', 'ge...   \n",
       "4  ['I', 'would', '\\n\\n', 'lately', 'I', 'find', ...   \n",
       "\n",
       "                                                Tags  \n",
       "0  ['ADV', 'ADP', 'PRON', 'SPACE', 'SCONJ', 'PRON...  \n",
       "1  ['VERB', 'PRON', 'NOUN', 'SPACE', 'DET', 'NOUN...  \n",
       "2  ['PROPN', 'PROPN', 'SPACE', 'DET', 'NOUN', 'PR...  \n",
       "3  ['NOUN', 'NOUN', 'SPACE', 'PROPN', 'PRON', 'VE...  \n",
       "4  ['PRON', 'AUX', 'SPACE', 'ADV', 'PRON', 'VERB'...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load metadata.\n",
    "metadata_df = pd.read_csv('one_direction_songs_detailed.csv')\n",
    "metadata_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b08e9cf3-5ce2-41bf-b9f9-67a55eb105e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove .txt from title of each paper\n",
    "paper_df['Filename'] = paper_df['Filename'].str.replace('.txt', '', regex=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
